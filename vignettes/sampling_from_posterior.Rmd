---
title: "Sampling From Posterior"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{sampling_from_posterior}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7
)
```

```{r setup}
library(sbmR)
library(tidyverse)
```


In this document we will explore how to use the function `mcmc_sweep()` to sample from the posterior of a simulated network and investigate the results of doing so. 


## Setting up network structure

First we will generate our simulated network. First we set a seed to make the structure reproducable and then we draw our random network using the `sim_basic_block_network()` function to draw from a network with 3 groups and 40 nodes per group. 

```{r}
set.seed(42)

group_info <- dplyr::tribble(
  ~group, ~n_nodes,
     "a",       20,
     "b",       22,
     "c",       25
)

connection_propensities <- dplyr::tribble(
 ~group_1, ~group_2, ~propensity,
      "a",      "a",         0.8,
      "a",      "b",         0.2,
      "a",      "c",         0.3,
      "b",      "b",         0.9,
      "b",      "c",         0.15,
      "c",      "c",         0.4,
)

network <- sim_sbm_network(group_info, connection_propensities, edge_dist = purrr::rbernoulli)
```


First we can make sure our connection propensities look reasonable 

```{r}
connection_propensities %>% 
  ggplot(aes(x = group_1, y = group_2, fill = propensity)) +
  geom_tile(color = 'white') +
  theme_bw()
```


Next, we can visualize the actual drawn network. 

```{r}
visualize_network(network, width = '100%')
```

We can see a decent amount of separation with perhaps more cohesion between the green and blue nodes than the orange


## Setting up SBM

Now that we have our data we can load it into an SBM object and look at the first few nodes worth of summary

```{r}
my_sbm <- create_sbm(network)

my_sbm %>% get_state() %>% head()
```


### Initializing the chain location

In an attempt to set our initial chain location to an optimal position we will agglomeratively merge the network using the collapse groups function. This will return a list of results for different model sizes. 

```{r}
collapse_results <- my_sbm %>% 
  collapse_groups(exhaustive = TRUE, num_group_proposals = 8, num_mcmc_sweeps = 25)
```


Let's look at the collapse results in terms of number of groups and the size of the network...

```{r}
ggplot(collapse_results, aes(x = num_groups, y = entropy)) +
  geom_line() +
  scale_x_log10() +
  geom_vline(xintercept = 3, color = 'orangered')
```

So even though we know our true number of groups is `3` we see a minimum entropy at `r collapse_results$num_groups[collapse_results$entropy == min(collapse_results$entropy)]` so we will start our chain there. To do this we will use the helper function `choose_best_collapse_state()` which will scan through the results and find the optimal partitioning based upon the designated hueristic. Right now it is just choosing the lowest value. (In the future more complicated methods will be allowed.)

```{r}
my_sbm <- my_sbm %>% choose_best_collapse_state(collapse_results, heuristic = 'lowest')
```


### Visualizing these results. We can use our visualization function to look at the results of this clustering and compare that to the known structure...

```{r}
merged_state <- my_sbm %>% 
  get_state() %>% 
  select(id, parent)

nodes_w_inferred_group <- network$nodes  %>%
  left_join(merged_state, by = 'id') %>% 
  rename(inferred = parent)

visualize_network(edges = network$edges, 
                  nodes = nodes_w_inferred_group, 
                  node_color_col = 'group', 
                  node_shape_col = 'inferred',
                  width = '100%')
```

It appears that our grouping is working decently well as the cluster of nodes that represent the orange group seem to be made up of the same types of shapes whereas the other groups are more mixed as we would expect. 

## Sampling from the posterior

Now that we have our model in a decent starting place we can initiate the MCMC sampling. We will start by doing 100 sweeps to see if our model shape has stabalized at all. 

```{r}
num_sweeps <- 1000

sweep_results <- 1:num_sweeps %>% 
  purrr::map(~mcmc_sweep(my_sbm))


sweep_results %>% 
  map_dfr(~tibble(
    n_moved = length(.$nodes_moved),
    entropy_delta = .$entropy_delta
  )) %>% 
  mutate(sweep = 1:n()) %>% 
  pivot_longer(-sweep, names_to = 'stat') %>% 
  ggplot(aes(x = sweep, y = value)) +
  geom_line() +
  facet_grid(stat~., scales = 'free_y') +
  labs(
    title = glue::glue('Result of {num_sweeps} MCMC sweeps'),
    subtitle = "Entropy Delta of sweep and number of nodes moved for sweep"
  )
```



```{r}
nodes_w_inferred_group <- my_sbm %>% 
  get_state() %>% 
  select(id, parent) %>% 
  right_join(network$nodes, by = 'id') %>% 
  rename(inferred = parent)

visualize_network(edges = network$edges, 
                  nodes = nodes_w_inferred_group, 
                  node_color_col = 'group', 
                  node_shape_col = 'inferred',
                  width = '100%')
```



